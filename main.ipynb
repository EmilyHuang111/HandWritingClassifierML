{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Frame the problem\n",
    "Using the customer description, Define the problem your trying to solve in your own words (remember this is not technial but must be specific so the customer understands the project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project uses hand written letter (a-z) images that were given by the client. This project aims to use multiple machine learning models such as convolutional neutral networks to predict the the correct letter of an image. The performance measure that will be used is accuracy score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Get the Data \n",
    "Define how you recieved the data (provided, gathered..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was provided by the client. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Explore the Data\n",
    "Gain insights into the data you have from step 2, making sure to identify any bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While exploring the data, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While exploring the data manually, I noticed that the file types were different for the files. Some files are heic while other files are jpg. The file names are also not the same. The lighting background noise is not the same. The centering of the letter is not the same. Some letters are uppercase while other files are lowercase. Some files don't have an extension in the name. Some files are named with uppercase letters while others are named with lowercase letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t.jpg: image/jpeg\n",
      "f.jpg: image/jpeg\n",
      "c.jpg: image/jpeg\n",
      "m.jpg: image/jpeg\n",
      "l.jpg: image/jpeg\n",
      "e.jpg: image/jpeg\n",
      "u.jpg: image/jpeg\n",
      "k.jpg: image/jpeg\n",
      "j.jpg: image/jpeg\n",
      "b.jpg: image/jpeg\n",
      "i.jpg: image/jpeg\n",
      "y.jpg: image/jpeg\n",
      "a.jpg: image/jpeg\n",
      "x.jpg: image/jpeg\n",
      "w.jpg: image/jpeg\n",
      "p.jpg: image/jpeg\n",
      "d.jpg: image/jpeg\n",
      "z.jpg: image/jpeg\n",
      "n.jpg: image/jpeg\n",
      "r.jpg: image/jpeg\n",
      "h.jpg: image/jpeg\n",
      "g.jpg: image/jpeg\n",
      "o.jpg: image/jpeg\n",
      "q.jpg: image/jpeg\n",
      "s.jpg: image/jpeg\n",
      "v.jpg: image/jpeg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import magic\n",
    "\n",
    "#S9 was a file that had no extension. \n",
    "def check_file_type(file_path):\n",
    "    try:\n",
    "        mime = magic.Magic(mime=True)\n",
    "        file_type = mime.from_file(file_path)\n",
    "        return file_type\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "#directory path\n",
    "directory_path = 'data/S9'\n",
    "\n",
    "if os.path.isdir(directory_path):\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        if os.path.isfile(file_path):  \n",
    "            file_type = check_file_type(file_path)\n",
    "            print(f\"{file_name}: {file_type}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I checked the file types for the directories that didn't have extensions (S8 and S12). I found out that these files were heic files. In later steps, I converted these files to jpg files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S1\n",
      "File: t.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 3024x4032 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def check_image_dimensions(directory):\n",
    "    if os.path.exists(directory):\n",
    "        print(f\"Checking dimensions and pixel sizes of files in directory: {directory}\")\n",
    "\n",
    "        for file_name in os.listdir(directory):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    #open the image file\n",
    "                    with Image.open(file_path) as img:\n",
    "                        #get dimensions and color mode\n",
    "                        width, height = img.size\n",
    "                        mode = img.mode  #color space (e.g., RGB, L, etc.)\n",
    "                        print(f\"File: {file_name} - Dimensions: {width}x{height} - Mode: {mode}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not open {file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"Directory {directory} does not exist.\")\n",
    "\n",
    "check_image_dimensions(os.path.join(\"data\", \"S1\")) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S1 directory. \n",
    "All dimensions are 3024x4032. \n",
    "These dimensions are pretty big. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S10\n",
      "File: t.jpg - Dimensions: 872x872 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 699x699 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 411x411 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 819x819 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 964x964 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 544x544 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 912x912 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 750x750 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 713x713 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 509x509 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 711x711 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 948x948 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 521x521 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 829x829 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 964x964 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 949x949 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 558x558 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 858x858 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 1056x1056 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 647x647 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 693x693 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 463x463 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 890x890 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 619x619 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 747x747 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 685x685 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S10\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S10 directory. I can see that all the dimensions are different for each image. The smallest image dimensions are 411x411. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S11\n",
      "File: t.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 3024x4032 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S11\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S11 directory. The dimensions are all consistent at 3024x4032.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S12\n",
      "File: t.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 3024x4032 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S12\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S12 directory. The dimensions are all consistent at 3024x4032. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S13\n",
      "File: t.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 3024x4032 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S13\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S13 directory. The dimensions are all consistent at 3024x4032. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S14\n",
      "File: t.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 3264x2448 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 3264x2448 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S14\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S14 directory. These dimensions are different from the consistent 3024x4032 that exists in the most of the other files. The dimensions above are all 3264x2448. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S2\n",
      "File: t.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 3024x4032 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S2 directory. The dimensions are all consistent at 3024x4032. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S3\n",
      "File: t.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 2854x3806 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 3024x4032 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S3 directory. The dimensions are all consistent at 3024x4032. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S4\n",
      "File: t.jpg - Dimensions: 3096x2252 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 3001x2252 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 3040x2252 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 2965x2252 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 3064x2252 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 2987x2252 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 3049x2252 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 2917x2252 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 3077x2252 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 2058x1526 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 4000x2252 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 3031x2252 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 2999x2251 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 3062x2252 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 2902x2252 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 3061x2252 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 2931x2252 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 3027x2252 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 2905x2252 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 3062x2252 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 3012x2252 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 3037x2252 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 3070x2252 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 3020x2252 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 2942x2252 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 3021x2252 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S4 directory. I can see that some dimensions are different for each image in this directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S5\n",
      "File: t.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 4032x3024 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S5 directory. The dimensions are all consistent at 4032x3024. However, this is different from the typical 3024x4032 dimensions. This could indicate that these photos were taken in landscape mode. Where as the majority of other photos were taken in portrait mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S6\n",
      "File: t.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 4032x3024 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 4032x3024 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S6\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S6 directory. The dimensions are all consistent at 4032x3024. However, this is different from the typical 3024x4032 dimensions. This could indicate that these photos were taken in landscape mode. Where as the majority of other photos were taken in portrait mode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S7\n",
      "File: t.jpg - Dimensions: 871x1081 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 826x1078 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 629x777 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 1130x996 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 785x1098 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 759x891 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 913x925 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 934x1138 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 795x1338 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 732x1087 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 771x1101 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 850x938 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 632x771 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 995x1100 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 881x695 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 749x1248 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 743x1056 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 704x809 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 1076x997 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 933x960 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 775x925 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 872x1187 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 844x987 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 1035x1373 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 939x1069 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 779x942 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S7\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S7 directory. I can see that all the images have different dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S8\n",
      "File: t.jpg - Dimensions: 1073x1730 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 1211x1807 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 1153x1853 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 1100x1544 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 982x1587 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 1001x1843 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 1334x1889 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 1083x1722 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 1071x1386 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 1349x2039 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 1010x1662 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 1134x1236 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 1124x1962 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 892x1422 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 1047x1623 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 1095x1899 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 1197x2013 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 1071x1108 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 1286x1955 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 1122x1984 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 1230x1797 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 1025x1631 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 786x1447 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 1073x1754 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 1277x2054 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 1478x1805 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S8 directory. I can see that all the images have different dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking dimensions and pixel sizes of files in directory: data/S9\n",
      "File: t.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: f.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: c.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: m.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: l.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: e.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: u.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: k.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: j.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: b.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: i.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: y.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: a.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: x.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: w.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: p.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: d.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: z.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: n.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: r.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: h.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: g.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: o.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: q.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: s.jpg - Dimensions: 3024x4032 - Mode: RGB\n",
      "File: v.jpg - Dimensions: 3024x4032 - Mode: RGB\n"
     ]
    }
   ],
   "source": [
    "check_image_dimensions(os.path.join(\"data\", \"S9\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I found the dimensions for the files in the S9 directory. The dimensions are all consistent at 3024x4032.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Prepare the Data\n",
    "\n",
    "\n",
    "Apply any data transformations and explain what and why\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install some packages\n",
    "pip install pyheif\n",
    "pip install python-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pyheif\n",
    "\n",
    "\n",
    "data_folder = \"./data/S9\"\n",
    "\n",
    "#loop through all files in the directory\n",
    "for filename in os.listdir(data_folder):\n",
    "    #check for files with .heic extension\n",
    "    if filename.lower().endswith(\".heic\"):\n",
    "        heic_path = os.path.join(data_folder, filename)\n",
    "        jpg_path = os.path.join(data_folder, f\"{os.path.splitext(filename)[0]}.jpg\")\n",
    "\n",
    "        #open and convert HEIC file \n",
    "        heif_file = pyheif.read(heic_path)\n",
    "        image = Image.frombytes(\n",
    "            heif_file.mode, heif_file.size, heif_file.data, \"raw\", heif_file.mode\n",
    "        )\n",
    "\n",
    "        #save as jpeg\n",
    "        image.save(jpg_path, \"JPEG\")\n",
    "        print(f\"Converted {filename} to {jpg_path}\")\n",
    "\n",
    "        #delete the original HEIC file\n",
    "        os.remove(heic_path)\n",
    "        print(f\"Deleted original HEIC file: {heic_path}\")\n",
    "\n",
    "print(\"All HEIC files have been converted to JPG and original HEIC files have been deleted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I changed all the heic files to jpg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "\n",
    "data_folder = \"./data/S5\"\n",
    "\n",
    "#get all image files \n",
    "image_files = [f for f in os.listdir(data_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.heic'))]\n",
    "\n",
    "#sort files to ensure consistent alphabetical ordering\n",
    "image_files.sort()\n",
    "\n",
    "#use letters from a to z for renaming\n",
    "alphabet = list(string.ascii_lowercase)\n",
    "\n",
    "#rename files\n",
    "for index, filename in enumerate(image_files):\n",
    "    if index >= len(alphabet):\n",
    "        print(\"Ran out of alphabet letters to rename files.\")\n",
    "        break\n",
    "\n",
    "    #define old and new paths\n",
    "    old_path = os.path.join(data_folder, filename)\n",
    "    new_name = f\"{alphabet[index]}.jpg\"  \n",
    "    new_path = os.path.join(data_folder, new_name)\n",
    "\n",
    "    #rename the file\n",
    "    os.rename(old_path, new_path)\n",
    "    print(f\"Renamed {filename} to {new_name}\")\n",
    "\n",
    "print(\"All images have been renamed from a to z.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I changed the names of some files to maintain consistent order (a-z) instead of IMG_123. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_folder = \"./data/S7\"\n",
    "\n",
    "#loop through all files in the specified directory\n",
    "for filename in os.listdir(data_folder):\n",
    "    #check if the file has an uppercase .JPG extension\n",
    "    if filename.lower().endswith(\".jpg\") and filename.endswith(\".JPG\"):\n",
    "        old_path = os.path.join(data_folder, filename)\n",
    "        #create new filename with lowercase .jpg extension\n",
    "        new_path = os.path.join(data_folder, f\"{os.path.splitext(filename)[0]}.jpg\")\n",
    "\n",
    "        #rename the file\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Renamed {filename} to {new_path}\")\n",
    "\n",
    "print(\"All .JPG files have been renamed to .jpg.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I changed all the the file extensions that had an uppercase JPG extension to become lowercase jpg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#define the directory containing the images\n",
    "data_folder = \"./data/S8\"\n",
    "\n",
    "#loop through all files in the specified directory\n",
    "for filename in os.listdir(data_folder):\n",
    "    #check if the file has no extension \n",
    "    if '.' not in filename:\n",
    "        old_path = os.path.join(data_folder, filename)\n",
    "        #create new filename with .jpg extension\n",
    "        new_path = os.path.join(data_folder, f\"{filename}.jpg\")\n",
    "\n",
    "        #rename the file\n",
    "        os.rename(old_path, new_path)\n",
    "        print(f\"Added .jpg extension to {filename}\")\n",
    "\n",
    "print(\"All files without an extension have been renamed to include .jpg.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the files that had no extension, I added a jpg extension to them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import magic\n",
    "from PIL import Image\n",
    "import pyheif\n",
    "\n",
    "s8_directory = os.path.join(\"data\", \"S12\")\n",
    "\n",
    "if os.path.exists(s8_directory):\n",
    "    print(f\"Checking and converting files in directory: {s8_directory}\")\n",
    "    for file_name in os.listdir(s8_directory):\n",
    "        file_path = os.path.join(s8_directory, file_name)\n",
    "        \n",
    "        #skip directories (like .ipynb_checkpoints)\n",
    "        if os.path.isdir(file_path):\n",
    "            continue\n",
    "        \n",
    "        #check if the file has a .jpg extension\n",
    "        if file_name.lower().endswith(\".jpg\"):\n",
    "            #verify if the actual file type is HEIC\n",
    "            mime = magic.Magic(mime=True)\n",
    "            file_type = mime.from_file(file_path)\n",
    "            \n",
    "            if file_type == \"image/heic\":\n",
    "                try:\n",
    "                    #read and convert the HEIC file\n",
    "                    heif_file = pyheif.read(file_path)\n",
    "                    image = Image.frombytes(\n",
    "                        heif_file.mode,\n",
    "                        heif_file.size,\n",
    "                        heif_file.data,\n",
    "                        \"raw\",\n",
    "                        heif_file.mode,\n",
    "                        heif_file.stride,\n",
    "                    )\n",
    "\n",
    "                    #save the image as a genuine JPEG\n",
    "                    genuine_jpg_path = os.path.splitext(file_path)[0] + \"_converted.jpg\"\n",
    "                    image.save(genuine_jpg_path, \"JPEG\")\n",
    "                    print(f\"Converted {file_name} to {genuine_jpg_path}\")\n",
    "                    #os.remove(file_path)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to convert {file_name}: {e}\")\n",
    "            else:\n",
    "                print(f\"{file_name} is already a valid JPEG.\")\n",
    "else:\n",
    "    print(f\"Directory {s8_directory} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I actually changed the files that had no extension. After exploring the data and realizing that the files were heic file types, here I changed them to the jpg file type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "s8_directory = os.path.join(\"data\", \"S12\")\n",
    "\n",
    "if os.path.exists(s8_directory):\n",
    "    print(f\"Renaming converted files in directory: {s8_directory}\")\n",
    "    for file_name in os.listdir(s8_directory):\n",
    "        #look for files with _converted.jpg in the name\n",
    "        if file_name.endswith(\"_converted.jpg\"):\n",
    "            #define the original path and new path\n",
    "            original_path = os.path.join(s8_directory, file_name)\n",
    "            new_file_name = file_name.replace(\"_converted\", \"\")\n",
    "            new_path = os.path.join(s8_directory, new_file_name)\n",
    "\n",
    "            #rename the file\n",
    "            os.rename(original_path, new_path)\n",
    "            print(f\"Renamed {file_name} to {new_file_name}\")\n",
    "else:\n",
    "    print(f\"Directory {s8_directory} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I renamed some of my files to to ensure consistent names for the all the files. This will help with the labeling of the files when I train my model and make predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "#path to the S13 directory\n",
    "s13_directory = os.path.join(\"data\", \"S13\")\n",
    "\n",
    "if os.path.exists(s13_directory):\n",
    "    print(f\"Deleting files not matching pattern in directory: {s13_directory}\")\n",
    "    \n",
    "    #define the regex pattern for valid file names\n",
    "    pattern = re.compile(r'^[a-z]+\\.jpg$')  \n",
    "    \n",
    "    for file_name in os.listdir(s13_directory):\n",
    "        file_path = os.path.join(s13_directory, file_name)\n",
    "\n",
    "        if os.path.isfile(file_path):\n",
    "            #check if the file name matches the pattern\n",
    "            if not pattern.match(file_name):\n",
    "                #if it doesn't match, delete the file\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted file: {file_name}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Directory {s13_directory} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I deleted the duplicate images that were in the S13 directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one directory, I manually changed all the file names from uppercase A-Z to lowercase a-z. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I finished all the file converting to ensure the same type and name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 03:33:36.658108: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-11 03:33:36.663352: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-11 03:33:36.679223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-11 03:33:36.702713: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-11 03:33:36.709692: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-11 03:33:37.935234: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#directory paths and parameters\n",
    "final_images_directory = \"final images\"\n",
    "source_directories = [\"data/S1\", \"data/S2\", \"data/S3\", \"data/S4\", \"data/S5\", \"data/S6\", \"data/S7\", \"data/S8\", \"data/S9\", \"data/S10\", \"data/S11\", \"data/S12\", \"data/S13\", \"data/S14\"]\n",
    "target_image_size = (1024, 1024)\n",
    "focal_parameters = {\n",
    "    \"S1\": ((512, 512), (650, 570)),\n",
    "    \"S2\": ((512, 512), (350, 350)),\n",
    "    \"S3\": ((480, 250), (300, 300)),\n",
    "    \"S4\": ((512, 512), (800, 870)),\n",
    "    \"S5\": ((512, 512), (350, 350)),\n",
    "    \"S6\": ((512, 512), (410, 900)),\n",
    "    \"S7\": ((512, 512), (1500, 1500)),\n",
    "    \"S8\": ((512, 512), (700, 650)),\n",
    "    \"S9\": ((512, 512), (400, 400)),\n",
    "    \"S10\": ((512, 512), (1000, 1000)),\n",
    "    \"S11\": ((450, 530), (289, 289)),\n",
    "    \"S12\": ((512, 512), (550, 670)),\n",
    "    \"S13\": ((360, 550), (370, 375)),\n",
    "    \"S14\": ((400, 540), (410, 410)),\n",
    "}\n",
    "\n",
    "#resize all the images to 1024x1024\n",
    "def resize_image(image, target_size):\n",
    "    return cv2.resize(image, target_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#crop image based on focal point\n",
    "def crop_and_resize(image, focal_point, crop_size):\n",
    "    center_x, center_y = focal_point\n",
    "    crop_width, crop_height = crop_size\n",
    "    crop_x1 = max(center_x - crop_width // 2, 0)\n",
    "    crop_x2 = min(center_x + crop_width // 2, image.shape[1])\n",
    "    crop_y1 = max(center_y - crop_height // 2, 0)\n",
    "    crop_y2 = min(center_y + crop_height // 2, image.shape[0])\n",
    "    cropped_image = image[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "    return cv2.resize(cropped_image, (250, 250), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#convert grayscale image to binary\n",
    "def convert_to_binary(image):\n",
    "    _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "#add noise to the 2D image\n",
    "def add_noise(image):\n",
    "    noise = np.random.randint(-25, 26, image.shape, dtype=np.int16)\n",
    "    noisy_image = np.clip(image.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
    "    return noisy_image\n",
    "\n",
    "#extract label from file name\n",
    "def extract_label(image_name, directory_name):\n",
    "    label = image_name[0]\n",
    "    return label.upper() if directory_name in [\"S1\", \"S2\", \"S3\", \"S4\", \"S5\"] else label.lower()\n",
    "\n",
    "#ensure final directory exists\n",
    "os.makedirs(final_images_directory, exist_ok=True)\n",
    "\n",
    "#save processed images\n",
    "def save_processed_image(image, directory_name, image_name):\n",
    "    save_dir = os.path.join(final_images_directory, directory_name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    save_path = os.path.join(save_dir, image_name)\n",
    "    cv2.imwrite(save_path, image)\n",
    "\n",
    "\n",
    "#main data pipeline\n",
    "def process_image_pipeline(cnn_model=True):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    #process each image in the source directories\n",
    "    for source_directory in source_directories:\n",
    "        directory_name = os.path.basename(source_directory)\n",
    "        for image_name in os.listdir(source_directory):\n",
    "            image_path = os.path.join(source_directory, image_name)\n",
    "            if not os.path.isfile(image_path):\n",
    "                continue\n",
    "            original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "            if original_image is None:\n",
    "                print(f\"Skipping {image_path}. Not a valid image.\")\n",
    "                continue\n",
    "\n",
    "            #resize, crop, and preprocess the image\n",
    "            resized_image = resize_image(original_image, target_image_size)\n",
    "            focal_point, crop_size = focal_parameters.get(directory_name, ((512, 512), (250, 250)))\n",
    "            cropped_resized_image = crop_and_resize(resized_image, focal_point, crop_size)\n",
    "            binary_image = convert_to_binary(cropped_resized_image)\n",
    "            noisy_image = add_noise(binary_image)\n",
    "\n",
    "            #normalize the image\n",
    "            normalized_image = noisy_image.astype(np.float32) / 255.0\n",
    "\n",
    "            #format image data for the model type\n",
    "            if cnn_model:\n",
    "                #CNN expects 3D array, add a channel dimension\n",
    "                image_data = np.expand_dims(normalized_image, axis=-1)\n",
    "            else:\n",
    "                #SVM expects 1D array\n",
    "                image_data = normalized_image.flatten()\n",
    "\n",
    "            #save image and label data\n",
    "            save_processed_image(noisy_image, directory_name, image_name)\n",
    "            label = extract_label(image_name, directory_name)\n",
    "            data.append(image_data)\n",
    "            labels.append(label)\n",
    "\n",
    "    #encode labels into integers\n",
    "    label_encoder = LabelEncoder()\n",
    "    encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "    if cnn_model:\n",
    "        #for CNN, convert integer labels to one-hot encoded format\n",
    "        num_classes = len(label_encoder.classes_)\n",
    "        print(f\"Number of classes: {num_classes}\")\n",
    "        encoded_labels = to_categorical(encoded_labels, num_classes=num_classes)\n",
    "    else:\n",
    "        #for SVM, keep labels as integers\n",
    "        encoded_labels = np.array(encoded_labels)\n",
    "\n",
    "    #convert data to a NumPy array\n",
    "    data = np.array(data)\n",
    "    if cnn_model:\n",
    "        data = data.reshape(-1, 250, 250, 1)\n",
    "\n",
    "    #return processed data, labels, and the label encoder\n",
    "    return data, encoded_labels, label_encoder\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model the data\n",
    "Using selected ML models, experment with your choices and describe your findings. Finish by selecting a Model to continue with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "#run the pipeline to get data and labels\n",
    "data, encoded_labels, label_encoder = process_image_pipeline(cnn_model=False)\n",
    "\n",
    "#prepare the data and labels for SVM\n",
    "X = data\n",
    "y = encoded_labels  \n",
    "\n",
    "#split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#initialize the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42) \n",
    "\n",
    "#train the SVM model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "#make predictions on the test set\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "#accuracy score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I can see the accuracy score for SVM is around 4 percent. This result means that the model is not performing well on unseen data. I will try a different model to see if my accuracy score improves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.0231 - loss: 4.2105 - val_accuracy: 0.0169 - val_loss: 3.9490\n",
      "Epoch 2/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.0342 - loss: 3.9487 - val_accuracy: 0.0000e+00 - val_loss: 3.9573\n",
      "Epoch 5/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0251 - loss: 3.9626 - val_accuracy: 0.0000e+00 - val_loss: 3.9661\n",
      "Epoch 11/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.0326 - loss: 3.9257 - val_accuracy: 0.0000e+00 - val_loss: 3.9578\n",
      "Epoch 12/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0150 - loss: 3.9583 - val_accuracy: 0.0000e+00 - val_loss: 3.9615\n",
      "Epoch 13/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0027 - loss: 3.9273 - val_accuracy: 0.0169 - val_loss: 3.9680\n",
      "Epoch 14/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0261 - loss: 3.9354 - val_accuracy: 0.0000e+00 - val_loss: 3.9580\n",
      "Epoch 15/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0428 - loss: 3.9432 - val_accuracy: 0.0000e+00 - val_loss: 3.9619\n",
      "Epoch 16/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0260 - loss: 3.9259 - val_accuracy: 0.0000e+00 - val_loss: 3.9609\n",
      "Epoch 17/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0665 - loss: 3.9114 - val_accuracy: 0.0000e+00 - val_loss: 3.9638\n",
      "Epoch 18/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0196 - loss: 3.9111 - val_accuracy: 0.0000e+00 - val_loss: 3.9588\n",
      "Epoch 19/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0298 - loss: 3.9300 - val_accuracy: 0.0000e+00 - val_loss: 3.9586\n",
      "Epoch 20/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0280 - loss: 3.8930 - val_accuracy: 0.0339 - val_loss: 3.9529\n",
      "Epoch 21/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0313 - loss: 3.8757 - val_accuracy: 0.0169 - val_loss: 3.9574\n",
      "Epoch 22/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0471 - loss: 3.8886 - val_accuracy: 0.0169 - val_loss: 3.9466\n",
      "Epoch 23/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0231 - loss: 3.9412 - val_accuracy: 0.0000e+00 - val_loss: 3.9575\n",
      "Epoch 24/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0452 - loss: 3.8867 - val_accuracy: 0.0000e+00 - val_loss: 3.9579\n",
      "Epoch 25/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0339 - loss: 3.8617 - val_accuracy: 0.0000e+00 - val_loss: 3.9562\n",
      "Epoch 26/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0422 - loss: 3.8558 - val_accuracy: 0.0339 - val_loss: 3.9478\n",
      "Epoch 27/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0413 - loss: 3.8281 - val_accuracy: 0.0169 - val_loss: 3.9579\n",
      "Epoch 28/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0313 - loss: 3.8850 - val_accuracy: 0.0000e+00 - val_loss: 3.9523\n",
      "Epoch 29/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0237 - loss: 3.8246 - val_accuracy: 0.0508 - val_loss: 3.9533\n",
      "Epoch 30/30\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.0581 - loss: 3.7546 - val_accuracy: 0.0169 - val_loss: 3.9605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.055\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "#run the pipeline to get data and labels\n",
    "data, labels, label_encoder = process_image_pipeline(cnn_model=True)\n",
    "\n",
    "#split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#get the input shape and number of classes\n",
    "input_shape = X_train.shape[1:]  #shape: (250, 250, 1)\n",
    "num_classes = y_train.shape[1]   #number of unique classes\n",
    "\n",
    "#define the CNN model\n",
    "def create_cnn_model(input_shape, num_classes, optimizer_type='adam', learning_rate=0.001, \n",
    "                     num_filters=[32, 64, 128], kernel_size=(3, 3), dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "\n",
    "    #layer 1\n",
    "    model.add(Conv2D(num_filters[0], kernel_size, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #layer 2\n",
    "    model.add(Conv2D(num_filters[1], kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #layer 3\n",
    "    model.add(Conv2D(num_filters[2], kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #flatten the output for dense layers\n",
    "    model.add(Flatten())\n",
    "\n",
    "    #fully connected layer 1\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))  # Dropout to prevent overfitting\n",
    "\n",
    "    #fully connected layer 2\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))  # Dropout to prevent overfitting\n",
    "\n",
    "    #output layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    #select optimizer\n",
    "    if optimizer_type == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_type == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported optimizer. Choose 'adam' or 'rmsprop'.\")\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "#define hyperparameters\n",
    "hyperparameters = {\n",
    "    'optimizer_type': 'rmsprop',\n",
    "    'num_filters': [32, 64, 128],\n",
    "    'learning_rate': 0.0001,\n",
    "    'kernel_size': (7, 7),\n",
    "    'dropout_rate': 0.7,\n",
    "    'epochs': 30,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "#create the CNN model with the specified hyperparameters\n",
    "cnn_model = create_cnn_model(input_shape, num_classes, \n",
    "                             optimizer_type=hyperparameters['optimizer_type'],\n",
    "                             learning_rate=hyperparameters['learning_rate'],\n",
    "                             num_filters=hyperparameters['num_filters'],\n",
    "                             kernel_size=hyperparameters['kernel_size'],\n",
    "                             dropout_rate=hyperparameters['dropout_rate'])\n",
    "\n",
    "#train the CNN model\n",
    "history = cnn_model.fit(X_train, y_train, \n",
    "                        validation_split=0.2, \n",
    "                        epochs=hyperparameters['epochs'], \n",
    "                        batch_size=hyperparameters['batch_size'], \n",
    "                        verbose=1)\n",
    "\n",
    "#save the trained model and label encoder\n",
    "cnn_model.save('cnn_model.h5')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "\n",
    "#accuracy score\n",
    "loss, accuracy = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test accuracy: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, I can see that my accuracy score is 9.6 percent with CNN. This performed better than the SVM model; however, the accuracy score is still very low. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Convolutional Neural network model performed the best, I will use it for hyperparameter tuning to try to get improved results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Fine Tune the Model\n",
    "\n",
    "With the select model descibe the steps taken to achieve the best results possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 52\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=30, model__dropout_rate=0.3, model__kernel_size=7, model__learning_rate=0.0001, model__num_filters=32, model__optimizer=rmsprop; total time= 6.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=30, model__dropout_rate=0.3, model__kernel_size=7, model__learning_rate=0.0001, model__num_filters=32, model__optimizer=rmsprop; total time= 6.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f7b983109d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f7b983109d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f7b983109d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f7b983109d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=64, epochs=30, model__dropout_rate=0.3, model__kernel_size=7, model__learning_rate=0.0001, model__num_filters=32, model__optimizer=rmsprop; total time= 6.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=16, epochs=30, model__dropout_rate=0.2, model__kernel_size=5, model__learning_rate=0.001, model__num_filters=128, model__optimizer=adam; total time=31.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=16, epochs=30, model__dropout_rate=0.2, model__kernel_size=5, model__learning_rate=0.001, model__num_filters=128, model__optimizer=adam; total time=31.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=16, epochs=30, model__dropout_rate=0.2, model__kernel_size=5, model__learning_rate=0.001, model__num_filters=128, model__optimizer=adam; total time=31.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=100, model__dropout_rate=0.2, model__kernel_size=3, model__learning_rate=0.01, model__num_filters=128, model__optimizer=rmsprop; total time=48.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=100, model__dropout_rate=0.2, model__kernel_size=3, model__learning_rate=0.01, model__num_filters=128, model__optimizer=rmsprop; total time=48.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=100, model__dropout_rate=0.2, model__kernel_size=3, model__learning_rate=0.01, model__num_filters=128, model__optimizer=rmsprop; total time=48.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=50, model__dropout_rate=0.7, model__kernel_size=3, model__learning_rate=0.01, model__num_filters=32, model__optimizer=adagrad; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=50, model__dropout_rate=0.7, model__kernel_size=3, model__learning_rate=0.01, model__num_filters=32, model__optimizer=adagrad; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=32, epochs=50, model__dropout_rate=0.7, model__kernel_size=3, model__learning_rate=0.01, model__num_filters=32, model__optimizer=adagrad; total time= 4.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=128, epochs=100, model__dropout_rate=0.5, model__kernel_size=3, model__learning_rate=1e-05, model__num_filters=128, model__optimizer=adam; total time=46.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=128, epochs=100, model__dropout_rate=0.5, model__kernel_size=3, model__learning_rate=1e-05, model__num_filters=128, model__optimizer=adam; total time=46.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=128, epochs=100, model__dropout_rate=0.5, model__kernel_size=3, model__learning_rate=1e-05, model__num_filters=128, model__optimizer=adam; total time=46.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=128, epochs=50, model__dropout_rate=0.5, model__kernel_size=7, model__learning_rate=0.001, model__num_filters=32, model__optimizer=adam; total time=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=128, epochs=50, model__dropout_rate=0.5, model__kernel_size=7, model__learning_rate=0.001, model__num_filters=32, model__optimizer=adam; total time=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=128, epochs=50, model__dropout_rate=0.5, model__kernel_size=7, model__learning_rate=0.001, model__num_filters=32, model__optimizer=adam; total time=11.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from scikeras.wrappers import KerasClassifier  \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adagrad, Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "\n",
    "#define the function to create the CNN model\n",
    "def create_cnn_model_with_params(optimizer='adam', learning_rate=0.001, num_filters=32, kernel_size=3, dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(num_filters, (kernel_size, kernel_size), activation='relu', input_shape=(250, 250, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(num_filters * 2, (kernel_size, kernel_size), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(num_filters * 4, (kernel_size, kernel_size), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    #define optimizer with selected type and learning rate\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = SGD(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'adagrad':\n",
    "        opt = Adagrad(learning_rate=learning_rate)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer}\")\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#wrap the model using KerasClassifier\n",
    "model = KerasClassifier(model=create_cnn_model_with_params, verbose=0)\n",
    "\n",
    "#define the hyperparameter space, including optimizers\n",
    "param_dist = {\n",
    "    'model__optimizer': ['adam', 'sgd', 'rmsprop', 'adagrad'],  \n",
    "    'model__learning_rate': [0.01, 0.001, 0.0001, 0.00001],\n",
    "    'model__num_filters': [16, 32, 64, 128],\n",
    "    'model__kernel_size': [3, 5, 7],\n",
    "    'model__dropout_rate': [0.2, 0.3, 0.5, 0.7],\n",
    "    'batch_size': [16, 32, 64, 128],\n",
    "    'epochs': [20, 30, 50, 100]\n",
    "}\n",
    "\n",
    "#process and split data\n",
    "data, labels, label_encoder = process_image_pipeline()\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "#split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "#set up randomized search with the updated parameter space\n",
    "random_search = RandomizedSearchCV(estimator=model,\n",
    "                                   param_distributions=param_dist,\n",
    "                                   n_iter=30,  \n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   random_state=42)\n",
    "\n",
    "#fit randomized search\n",
    "random_search_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "#output the best hyperparameters and evaluate the best model\n",
    "print(\"Best Hyperparameters:\", random_search_result.best_params_)\n",
    "\n",
    "#accuracy score and best hyperparameters\n",
    "best_model = random_search_result.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(f\"Test Accuracy with Best Hyperparameters: {test_score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 5 iterations and changing the parameter ranges, these are my results for the best parameters:\n",
    "'model__optimizer': 'adam', 'model__num_filters': 32, 'model__learning_rate': 0.001, 'model__kernel_size': 3, 'model__dropout_rate': 0.5, 'epochs': 30, 'batch_size': 64\n",
    "Accuracy score: 4.1%\n",
    "\n",
    "After 10 iterations and changing the parameter ranges, these are my results for the best parameters:\n",
    "'model__optimizer': 'rmsprop', 'model__num_filters': 64, 'model__learning_rate': 0.0001, 'model__kernel_size': 5, 'model__dropout_rate': 0.5, 'epochs': 30, 'batch_size': 64\n",
    "Accuracy score: 4.33%\n",
    "\n",
    "After 15 iterations and changing the parameter ranges, these are my results for the best parameters:\n",
    "'model__optimizer': 'rmsprop', 'model__num_filters': 32, 'model__learning_rate': 0.0001, 'model__kernel_size': 7, 'model__dropout_rate': 0.3, 'epochs': 30, 'batch_size': 64\n",
    "Accuracy score: 5.5%\n",
    "\n",
    "After 20 iterations and changing the parameter ranges, these are my results for the best parameters:\n",
    "'model__optimizer': 'adam', 'model__num_filters': 32, 'model__learning_rate': 0.0001, 'model__kernel_size': 7, 'model__dropout_rate': 0.3, 'epochs': 30, 'batch_size': 32\n",
    "Accuracy score: 8.2%\n",
    "\n",
    "After 30 iterations and changing the parameter ranges, these are my results for the best parameters:\n",
    "'model__optimizer': 'rmsprop', 'model__num_filters': 32, 'model__learning_rate': 0.0001, 'model__kernel_size': 7, 'model__dropout_rate': 0.7, 'epochs': 30, 'batch_size': 32\n",
    "Accuracy score: 10.1%\n",
    "\n",
    "I got improved results after 30 iterations of hyperparameter tuning! This took hours to find the better parameters in order to improve my model accuracy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Present\n",
    "In a customer faceing Document provide summery of finding and detail approach taken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand Written Letter Prediction\n",
    "The client has tasked me to predict the letter (a-z) of the hand written images. \n",
    "\n",
    "First, I explored the data data and looked for relationships between the hand written images. \n",
    "\n",
    "- I realized the file names were not the same. \n",
    "- I realized the file extensions were not the same. \n",
    "- I realized that the file types were not the same. \n",
    "- I realized some files had no extension, but in reality they were HEIC files. \n",
    "- Some handwritten images were written in uppercase while others were written in lowercase. \n",
    "- The images were not written by the same person. Thus, the lighting, the angles of the image, the size, and the position of the letters are different. \n",
    "- The images were all taken with different phones. Hence, the dimensions of the images were different.  \n",
    "\n",
    "Next, I applied some data transformations using a data pipeline: \n",
    "- Maintained the same file type of jpg and extension of .jpg. \n",
    "- Maintained the same file names of (a-z).\n",
    "- Found focal point and cropped around the letter.\n",
    "- Resize all image dimensions to 250x250.\n",
    "- Convert images to black and white binary. \n",
    "- Add noise to all the images.\n",
    "- Normalize the images.\n",
    "- Flatten images if necessary.\n",
    "- Encode labels into integers and convert labels to one hot encoded format if necessary. \n",
    "\n",
    "Then I tested 2 different models: \n",
    "- Support Vector Machines (SVM)\n",
    "- Convolutional neural networks (CNN)\n",
    "\n",
    "I noticed that adding random noise improved my model accuracy by 2%!\n",
    "\n",
    "The convolutional neural network model performed the best out of all the models with an Accuracy Score of 9.6% before hyperparameter tuning. \n",
    "\n",
    "Then, I tuned my model with Randomized Search and I got improved results!\n",
    "\n",
    "The final results are: \n",
    "\n",
    "-Accuracy Score: 10.1%\n",
    "\n",
    "Overall, these results are not good. \n",
    "\n",
    "Several factors contributing to the bad results:\n",
    "\n",
    "- The dataset was very small. This limited number of training samples may not provide enough variation for the model to generalize well.\n",
    "- The inconsistent handwriting styles across individuals, combined with variations in the positioning of letters on the paper, introduced significant variability. Even after preprocessing the data, these factors likely contributed to the model's reduced performance.\n",
    "- The variations in lighting, angles, and sizes of the handwritten letters likely contributed to the model's reduced performance.\n",
    "- The quality of the images was not optimal. Some images were slightly blurry, which may have negatively impacted the model's performance.\n",
    "- The handwriting of certain letters didnt resemble the actual letter. Some people wrote their letters in unique or unconventional ways, making them difficult for the model to recognize or classify accurately.\n",
    "- The cropping process that I used to remove the background may not have been effective enough to yield good results. Poorly defined crop regions could have resulted in off-centered characters, making it harder for the model to accurately recognize them.\n",
    "- The preprocessing method I selected may not have been the most effective for achieving the best model performance.  \n",
    "- Additionally, the focal points I chose for cropping might not have been the best position, potentially impacting my model's performance negatively. \n",
    "\n",
    "\n",
    "Possible additional steps to improve the model:\n",
    "- Try a different data processing technique to see if I get improved results. Such as experimenting with Gaussian Blur or Canny Edge Detection techniques during image processing to identify the letter then crop the surrounding background.  \n",
    "- Test a range of hyperparameter values to fine-tune the model and evaluate potential performance improvements.  \n",
    "- Adjust various parameters in the CNN model to explore their impact on achieving better results.  \n",
    "- Experiment with applying random adjustments to brightness, contrast, and blur to evaluate their potential impact on improving model performance. \n",
    "- Try a different performance measure. \n",
    "- Test various image dimensions to determine if they can enhance the model's performance.\n",
    "- Try changing the order of the preprocessing steps in my current data pipeline to assess whether it leads to improved results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Launch the Model System\n",
    "Define your production run code, This should be self susficent and require only your model pramaters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-15 14:07:04.362153: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-15 14:07:04.367709: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-15 14:07:04.383301: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-15 14:07:04.407554: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-15 14:07:04.414810: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-15 14:07:05.626661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step\n",
      "Predicted Letter: s\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "#inference function\n",
    "def inference(image_path, model_path='cnn_model.h5', encoder_path='label_encoder.pkl'):\n",
    "    #load the trained model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    #load the label encoder\n",
    "    label_encoder = joblib.load(encoder_path)\n",
    "\n",
    "    #preprocess the input image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Invalid image path or unreadable image.\")\n",
    "    \n",
    "    #resize the image to the required input size\n",
    "    image_resized = cv2.resize(image, (250, 250), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    #convert to binary image\n",
    "    _, binary_image = cv2.threshold(image_resized, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    #normalize the image\n",
    "    normalized_image = binary_image.astype(np.float32) / 255.0 \n",
    "\n",
    "    #add channel dimension\n",
    "    input_data = np.expand_dims(normalized_image, axis=-1)\n",
    "    input_data = np.expand_dims(input_data, axis=0) \n",
    "\n",
    "    #predict the label\n",
    "    predictions = model.predict(input_data)\n",
    "    predicted_label_index = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "    #decode the label\n",
    "    results = label_encoder.inverse_transform([predicted_label_index])[0]\n",
    "\n",
    "    return results\n",
    "\n",
    "image_path = 'data/S1/s.jpg'\n",
    "\n",
    "#predict the letter\n",
    "predicted_letter = inference(image_path)\n",
    "print(f\"Predicted Letter: {predicted_letter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
